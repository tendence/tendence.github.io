#将PLSA和LDA模型跟《PRML》其他隐变量模型建立联系
如果我们撇开其他的模型，单独看PLSA模型，确实很神奇，但是略显孤独，如果我们能够把这个模型跟其他的模型建立一种联系，那这就会变得非常有趣，也将会有利于我们更好地了解PLSA模型。
我基本上看完了Bishop的大作《PRML》，所以这篇小文我会尝试建立PLSA模型跟PPCA，GMM，HMM，以及卡尔曼滤波之间关系。
事实上，跟PLSA关系最接近的是GMM模型，隐藏层都是离散的，PLSA的可见层是离散的，而GMM的可见层是连续的。
PLSA模型：
$$
p(z = z_k) = \pi_k; \\ 
\sum_k\pi_k=1;\\
p(x|z) = \prod\limits_{i=1}^D\prod_{k=1}^K\mu_{i,k}^{x_iz_k} 
$$
而在GMM中只要改最后一个式子


$$
p(x|z) = \prod\limits_{k=1}^K\mathcal{N}(x|\mu_k,\Sigma_k)^{z_k}
$$
PPCA也有隐藏层，但是其隐藏层是连续的，模型是这样的
$$
p(z)=\mathcal{N}(z|0,I);\\
p(x|z)=\mathcal{N}(x|Wz+\mu,\sigma^2I)
$$
以上的情况下隐变量时独立同分布的，如果不是独立同分布，而是放松一下约束，改成马尔科夫链关系，那么则形成了HMM（离散）和卡尔曼滤波（连续），而HMM的可见变量可以任意是连续或者离散，卡尔曼的可见只能是连续的
HMM模型
$$
p(z_n|z_{n-1},A) = \prod\limits_{k=1}^K\prod\limits_{j=1}^K
A_{jk}^{z_{n-1,j}z_{nk}};\\
p(z_1|\pi)=\prod_{k=1}^K\pi_k^{z_{1k}}
$$
而卡尔曼滤波中的隐变量的关系则是
$$
p(z_n|z_{n-1})=\mathcal{N}(z_n|Az_{n-1},\Gamma);\\
p(z_1)=\mathcal{N}(z_n|\mu_0,V_0);
p(x_n|z_n)=\mathcal{N}(x_n|Cz_n,\Sigma)
$$
总结：
如果隐变量独立，则有三种情况：
1，隐变量是离散，可见变量连续，模型是GMM
2，隐变量离散，可见变量离散，模型是PLSA
3，隐变量连续，可见变量连续，模型是PPCA
如果隐变量有马尔科夫链关系，也有三种情况
1，隐变量是离散，可见变量连续，模型是HMM
2，隐变量离散，可见变量离散，模型是HMM
3，隐变量连续，可见变量连续，模型是卡尔曼滤波

如果加入贝叶斯框架，则隐变量是独立的推导还能接受，如果有马尔科夫关系的话，则难度增加太多。在《PRML》中有GMM的贝叶斯框架，用一类变分推断推导。